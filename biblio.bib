@article{cascella2024,
	author = {Cascella, Marco and Semeraro, Federico and Montomoli, Jonathan and Bellini, Valentina and Piazza, Ornella and Bignami, Elena},
	date = {2024/02/17},
	date-added = {2024-04-15 09:56:29 +0200},
	date-modified = {2024-04-15 09:56:29 +0200},
	doi = {10.1007/s10916-024-02045-3},
	id = {Cascella2024},
	isbn = {1573-689X},
	journal = {Journal of Medical Systems},
	number = {1},
	pages = {22},
	title = {The Breakthrough of Large Language Models Release for Medical Applications: 1-Year Timeline and Perspectives},
	volume = {48},
	year = {2024},
	bdsk-url-1 = {https://doi.org/10.1007/s10916-024-02045-3}}




@inproceedings{MontagnaTELMED2024,
    author = {Montagna, Sara and Aguzzi, Gianluca and Stefano Ferretti and Lorenz Cuno Klopfenstein and Martino Francesco Pengo and Michelangelo Ungolo and Magnini, Matteo},
    keywords = {large language model, medical chatbot, chronic disease management},
    title = {{LLM}-based Solutions for Healthcare Chatbots: a Comparative Analysis},
    booktitle={IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops)}, 
    year = {2024},
    note = {Workshop proceedings are still not available on the IEEE Digital Library. In the interest of the reviewers, the paper pre-print is available at the following URL.},
    url = {https://apice.unibo.it/xwiki/bin/download/Publication/LlmBasedHealthcareChatbotsTelmed2024/a72-montagna%20final.pdf?rev=1.1}
}



@article{lancet2023,
	author = {Li, Hanzhou and Moon, John T and Purkayastha, Saptarshi and Celi, Leo Anthony and Trivedi, Hari and Gichoya, Judy W},
	doi = {10.1016/S2589-7500(23)00083-3},
	isbn = {2589-7500},
	journal = {The Lancet Digital Health},
	journal1 = {The Lancet Digital Health},
	month = {2024/01/22},
	number = {6},
	pages = {e333--e335},
	publisher = {Elsevier},
	title = {Ethics of large language models in medicine and medical research},
	type = {doi: 10.1016/S2589-7500(23)00083-3},
	volume = {5},
	year = {2023},
	year1 = {2023},
	bdsk-url-1 = {https://doi.org/10.1016/S2589-7500(23)00083-3}}



@article{Tian2023,
    author = {Tian, Shubo and Jin, Qiao and Yeganova, Lana and Lai, Po-Ting and Zhu, Qingqing and Chen, Xiuying and Yang, Yifan and Chen, Qingyu and Kim, Won and Comeau, Donald C and Islamaj, Rezarta and Kapoor, Aadit and Gao, Xin and Lu, Zhiyong},
    title = "{Opportunities and challenges for ChatGPT and large language models in biomedicine and health}",
    journal = {Briefings in Bioinformatics},
    volume = {25},
    number = {1},
    pages = {bbad493},
    year = {2024},
    month = {01},
    issn = {1477-4054},
    doi = {10.1093/bib/bbad493}
}




@article{BANERJEE2023100026,
title = {Large language modeling and classical {AI} methods for the future of healthcare},
journal = {Journal of Medicine, Surgery, and Public Health},
volume = {1},
pages = {100026},
year = {2023},
issn = {2949-916X},
doi = {https://doi.org/10.1016/j.glmedi.2023.100026},
author = {Sri Banerjee and Pat Dunn and Scott Conard and Roger Ng}
}

@article{https://doi.org/10.1002/ctm2.1216,
author = {Xue, Vivian Weiwen and Lei, Pinggui and Cho, William C.},
title = {The potential impact of ChatGPT in clinical and translational medicine},
journal = {Clinical and Translational Medicine},
volume = {13},
number = {3},
pages = {e1216},
doi = {https://doi.org/10.1002/ctm2.1216},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/ctm2.1216},
year = {2023}
}


@article{Clusmann2023,
	abstract = {Large language models (LLMs) are artificial intelligence (AI) tools specifically trained to process and generate text. LLMs attracted substantial public attention after OpenAI's ChatGPT was made publicly available in November 2022. LLMs can often answer questions, summarize, paraphrase and translate text on a level that is nearly indistinguishable from human capabilities. The possibility to actively interact with models like ChatGPT makes LLMs attractive tools in various fields, including medicine. While these models have the potential to democratize medical knowledge and facilitate access to healthcare, they could equally distribute misinformation and exacerbate scientific misconduct due to a lack of accountability and transparency. In this article, we provide a systematic and comprehensive overview of the potentials and limitations of LLMs in clinical practice, medical research and medical education.},
	author = {Clusmann, Jan and Kolbinger, Fiona R. and Muti, Hannah Sophie and Carrero, Zunamys I. and Eckardt, Jan-Niklas and Laleh, Narmin Ghaffari and L{\"o}ffler, Chiara Maria Lavinia and Schwarzkopf, Sophie-Caroline and Unger, Michaela and Veldhuizen, Gregory P. and Wagner, Sophia J. and Kather, Jakob Nikolas},
	doi = {10.1038/s43856-023-00370-1},
	id = {Clusmann2023},
	isbn = {2730-664X},
	journal = {Communications Medicine},
	number = {1},
	pages = {141},
	title = {The future landscape of large language models in medicine},
	volume = {3},
	year = {2023}}



@article{Thirunavukarasu2023,
	abstract = {Large language models (LLMs) can respond to free-text queries without being specifically trained in the task in question, causing excitement and concern about their use in healthcare settings. ChatGPT is a generative artificial intelligence (AI) chatbot produced through sophisticated fine-tuning of an LLM, and other tools are emerging through similar developmental processes. Here we outline how LLM applications such as ChatGPT are developed, and we discuss how they are being leveraged in clinical settings. We consider the strengths and limitations of LLMs and their potential to improve the efficiency and effectiveness of clinical, educational and research work in medicine. LLM chatbots have already been deployed in a range of biomedical contexts, with impressive but mixed results. This review acts as a primer for interested clinicians, who will determine if and how LLM technology is used in healthcare for the benefit of patients and practitioners.},
	author = {Thirunavukarasu, Arun James and Ting, Darren Shu Jeng and Elangovan, Kabilan and Gutierrez, Laura and Tan, Ting Fang and Ting, Daniel Shu Wei},
	date = {2023/08/01},
	date-added = {2023-11-17 15:22:31 +0100},
	date-modified = {2023-11-17 15:22:31 +0100},
	doi = {10.1038/s41591-023-02448-8},
	id = {Thirunavukarasu2023},
	isbn = {1546-170X},
	journal = {Nature Medicine},
	number = {8},
	pages = {1930--1940},
	title = {Large language models in medicine},
	volume = {29},
	year = {2023}}



@article{Peng2023,
	abstract = {There are enormous enthusiasm and concerns in applying large language models (LLMs) to healthcare. Yet current assumptions are based on general-purpose LLMs such as ChatGPT, which are not developed for medical use. This study develops a generative clinical LLM, GatorTronGPT, using 277 billion words of text including (1) 82 billion words of clinical text from 126 clinical departments and approximately 2 million patients at the University of Florida Health and (2) 195 billion words of diverse general English text. We train GatorTronGPT using a GPT-3 architecture with up to 20 billion parameters and evaluate its utility for biomedical natural language processing (NLP) and healthcare text generation. GatorTronGPT improves biomedical natural language processing. We apply GatorTronGPT to generate 20 billion words of synthetic text. Synthetic NLP models trained using synthetic text generated by GatorTronGPT outperform models trained using real-world clinical text. Physicians'Turing test using 1 (worst) to 9 (best) scale shows that there are no significant differences in linguistic readability (p = 0.22; 6.57 of GatorTronGPT compared with 6.93 of human) and clinical relevance (p = 0.91; 7.0 of GatorTronGPT compared with 6.97 of human) and that physicians cannot differentiate them (p < 0.001). This study provides insights into the opportunities and challenges of LLMs for medical research and healthcare.},
	author = {Peng, Cheng and Yang, Xi and Chen, Aokun and Smith, Kaleb E. and PourNejatian, Nima and Costa, Anthony B. and Martin, Cheryl and Flores, Mona G. and Zhang, Ying and Magoc, Tanja and Lipori, Gloria and Mitchell, Duane A. and Ospina, Naykky S. and Ahmed, Mustafa M. and Hogan, William R. and Shenkman, Elizabeth A. and Guo, Yi and Bian, Jiang and Wu, Yonghui},
	date = {2023/11/16},
	date-added = {2023-11-17 15:27:10 +0100},
	date-modified = {2023-11-17 15:27:10 +0100},
	doi = {10.1038/s41746-023-00958-w},
	id = {Peng2023},
	isbn = {2398-6352},
	journal = {npj Digital Medicine},
	number = {1},
	pages = {210},
	title = {A study of generative large language model for medical research and healthcare},
	volume = {6},
	year = {2023}}

@article{BIRKUN2024102048,
title = {Large Language Model-based Chatbot as a Source of Advice on First Aid in Heart Attack},
journal = {Current Problems in Cardiology},
volume = {49},
number = {1, Part A},
pages = {102048},
year = {2024},
issn = {0146-2806},
doi = {https://doi.org/10.1016/j.cpcardiol.2023.102048},
author = {Alexei A. Birkun and Adhish Gautam},
abstract = {The ability of the cutting-edge large language model-powered chatbots to generate human-like answers to user questions hypothetically could be utilized for providing real-time advice on first aid for witnesses of cardiovascular emergencies. This study aimed to evaluate quality of the chatbot responses to inquiries on help in heart attack. The study simulated interrogation of the new Bing chatbot (Microsoft Corporation, USA) with the “heart attack what to do” prompt coming from 3 countries, the Gambia, India and the USA. The chatbot responses (20 per country) were evaluated for congruence with the International First Aid, Resuscitation, and Education Guidelines 2020 using a checklist. For all user inquiries, the chatbot provided answers containing some guidance on first aid. However, the responses commonly left out some potentially life-saving instructions, for instance to encourage the person to stop physical activity, to take antianginal medication, or to start cardiopulmonary resuscitation for unresponsive abnormally breathing person. Mean percentage of the responses having full congruence with the checklist criteria varied from 7.3 for India to 16.8 for the USA. A quarter of responses for the Gambia and the USA, and 45.0% for India contained superfluous guidelines-inconsistent directives. The chatbot advice on help in heart attack has omissions, inaccuracies and misleading instructions, and therefore the chatbot cannot be recommended as a credible source of information on first aid. Active research and organizational efforts are needed to mitigate the risk of uncontrolled misinformation and establish measures for guaranteeing trustworthiness of the chatbot-mediated counseling.}
}


@article{Mancusi2022,
author = {Mancusi, Costantino and Bisogni, Valeria  et al.},
title = {Accuracy of home blood pressure measurement: the ACCURAPRESS study – a proposal of Young Investigator Group of the Italian Hypertension Society (Società Italiana dell’Ipertensione Arteriosa)},
journal = {Blood Pressure},
volume = {31},
number = {1},
pages = {297-304},
year = {2022},
publisher = {Taylor & Francis},
doi = {10.1080/08037051.2022.2137461}
}
%and Alessandro Maloberti, Maria Virginia Manzi, Valeria Visco, Marco Biolcati, Valentina Giani, Francesco Spannella, Silvia Monticone, Francesca Saladini, Giulia Rivasi, Giada Turrin, Giacomo Pucci, Martino Pengo, Fabio Bertacchini, Claudio Ferri, Guido Grassi, Maria Lorenza Muiesan},

@inproceedings{MontagnaGoodIT2023, 
    author = {Montagna, Sara and Ferretti, Stefano and Klopfenstein, Lorenz Cuno and Florio, Antonio and Pengo, Martino Francesco}, 
    title = {Data Decentralisation of {LLM}-Based Chatbot Systems in Chronic Disease Self-Management},   
    year = {2023}, 
    isbn = {9798400701160}, 
    publisher = {Association for Computing Machinery}, 
    address = {New York, NY, USA}, 
    doi = {10.1145/3582515.3609536}, 
    booktitle = {Proceedings of the 2023 ACM Conference on Information Technology for Social Good}, 
    pages = {205–212}, 
    numpages = {8}, 
    keywords = {chatbot, hypertension, personal data store, healthcare data privacy}, location = {Lisbon, Portugal}, 
    series = {GoodIT '23} 
}


@ARTICLE{Sulis2023,
	author = {Sulis, Emilio and Mariani, Stefano and Montagna, Sara},
	title = {A survey on agents applications in healthcare: Opportunities, challenges and trends},
	year = {2023},
	journal = {Computer Methods and Programs in Biomedicine},
	volume = {236},
	doi = {10.1016/j.cmpb.2023.107525},
	type = {Article}
}

@article{3419368,
  author       = {Sarah Masud Preum and
                  Sirajum Munir and
                  Meiyi Ma and
                  Mohammad Samin Yasar and
                  David J. Stone and
                  Ronald D. Williams and
                  Homa Alemzadeh and
                  John A. Stankovic},
  title        = {A Review of Cognitive Assistants for Healthcare: Trends, Prospects,
                  and Future Directions},
  journal      = {{ACM} Comput. Surv.},
  volume       = {53},
  number       = {6},
  pages        = {130:1--130:37},
  year         = {2021},
  url          = {https://doi.org/10.1145/3419368},
  doi          = {10.1145/3419368},
  timestamp    = {Sat, 08 Jan 2022 02:23:06 +0100},
  biburl       = {https://dblp.org/rec/journals/csur/PreumMMYSWAS21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@article{psycoLLM2024,
	abstract = {Large language models (LLMS) emerge as the most promising Natural Language Processing approach for clinical practice acceleration (i.e., diagnosis, prevention and treatment procedures). Similarly, intelligent conversational systems that leverage LLMS have disruptively become the future of therapy in the era of Chatgpt. Accordingly, this research addresses the application of LLMS in healthcare, paying particular attention to two relevant use cases: cognitive decline and depression, more specifically, postpartum depression. In the end, the most promising opportunities they represent (e.g., clinical tasks augmentation, personalized healthcare, etc.) and related concerns (e.g., data privacy and quality, fairness, etc.) are discussed to contribute to the global debate on their integration in the sanitary system.},
	author = {Garc{\'\i}a-M{\'e}ndez, Silvia and de Arriba-P{\'e}rez, Francisco},
	date = {2024/02/03},
	date-added = {2024-04-15 09:50:32 +0200},
	date-modified = {2024-04-15 09:50:32 +0200},
	doi = {10.1007/s10439-024-03454-8},
	id = {Garc{\'\i}a-M{\'e}ndez2024},
	isbn = {1573-9686},
	journal = {Annals of Biomedical Engineering},
	title = {Large Language Models and Healthcare Alliance: Potential and Challenges of Two Representative Use Cases},
	url = {https://doi.org/10.1007/s10439-024-03454-8},
	year = {2024},
	bdsk-url-1 = {https://doi.org/10.1007/s10439-024-03454-8}}


@Article{Wang2023,
    author="Wang, Changyu and Liu, Siru and Yang, Hao and Guo, Jiulin and Wu, Yuxuan and Liu, Jialin",
    title={{Ethical Considerations of Using ChatGPT in Health Care}},
    journal="Journal of Medical Internet Research",
    year="2023",
    month="Aug",
    day="11",
    volume="25",
    pages="e48009",
    keywords="ethics; ChatGPT; artificial intelligence; AI; large language models; health care; artificial intelligence development; development; algorithm; patient safety; patient privacy; safety; privacy",
    issn="1438-8871",
    doi="10.2196/48009"
}


@article{Mesko2023,
  author       = {Bertalan Mesk{\'{o}} and
                  Eric J. Topol},
  title        = {The imperative for regulatory oversight of large language models (or
                  generative {AI)} in healthcare},
  journal      = {npj Digit. Medicine},
  volume       = {6},
  year         = {2023},
  doi          = {10.1038/S41746-023-00873-0},
  timestamp    = {Sun, 31 Dec 2023 19:06:51 +0100},
  biburl       = {https://dblp.org/rec/journals/npjdm/MeskoT23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@article{nas-bert,
  author       = {Jin Xu and
                  Xu Tan and
                  Renqian Luo and
                  Kaitao Song and
                  Jian Li and
                  Tao Qin and
                  Tie{-}Yan Liu},
  title        = {{NAS-BERT:} Task-Agnostic and Adaptive-Size {BERT} Compression with
                  Neural Architecture Search},
  journal      = {CoRR},
  volume       = {abs/2105.14444},
  year         = {2021},
  url          = {https://arxiv.org/abs/2105.14444},
  eprinttype    = {arXiv},
  eprint       = {2105.14444},
  timestamp    = {Mon, 16 Aug 2021 15:03:27 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2105-14444.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{Zichichi20224515,
	author = {Zichichi, Mirko and Ferretti, Stefano and D’Angelo, Gabriele and Rodríguez-Doncel, Víctor},
	title = {Data governance through a multi-DLT architecture in view of the {GDPR}},
	year = {2022},
	journal = {Cluster Computing},
	volume = {25},
	number = {6},
	pages = {4515 – 4542},
	doi = {10.1007/s10586-022-03691-3},
	type = {Article}
}

@misc{gdpr,
  title = {Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation)},
  author = {{European Parliament} and {Council of the European Union}},
  year = {2016},
  howpublished = {Official Journal of the European Union},
  url = {https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32016R0679},
}

@misc{hipaa,
    title = {{Health Insurance Portability and Accountability Act of 1996 (HIPAA)}}, 
    author = {Act of Congress enacted by the 104th United States Congress},
    year = {1996},
    howpublished = {Public law 104},
    note = {191}}


@article{llama2,
  author       = {Hugo Touvron and others},
  title        = {Llama 2: Open Foundation and Fine-Tuned Chat Models},
  journal      = {CoRR},
  volume       = {abs/2307.09288},
  year         = {2023},
  doi          = {10.48550/ARXIV.2307.09288},
  eprinttype    = {arXiv},
  eprint       = {2307.09288},
  timestamp    = {Mon, 28 Aug 2023 21:26:22 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2307-09288.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{mistral,
  author       = {Albert Q. Jiang et al.},
  title        = {Mistral 7B},
  journal      = {CoRR},
  volume       = {abs/2310.06825},
  year         = {2023},
  doi          = {10.48550/ARXIV.2310.06825},
  eprinttype    = {arXiv},
  eprint       = {2310.06825},
  timestamp    = {Thu, 26 Oct 2023 16:46:26 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2310-06825.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{fastchat,
  author       = {Lianmin Zheng and
                  Wei{-}Lin Chiang and
                  Ying Sheng and
                  Siyuan Zhuang and
                  Zhanghao Wu and
                  Yonghao Zhuang and
                  Zi Lin and
                  Zhuohan Li and
                  Dacheng Li and
                  Eric P. Xing and
                  Hao Zhang and
                  Joseph E. Gonzalez and
                  Ion Stoica},
  editor       = {Alice Oh and
                  Tristan Naumann and
                  Amir Globerson and
                  Kate Saenko and
                  Moritz Hardt and
                  Sergey Levine},
  title        = {Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena},
  booktitle    = {Advances in Neural Information Processing Systems 36: Annual Conference
                  on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans,
                  LA, USA, December 10 - 16, 2023},
  year         = {2023},
  url          = {http://papers.nips.cc/paper\_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets\_and\_Benchmarks.html},
  timestamp    = {Fri, 05 Apr 2024 16:28:37 +0200},
  biburl       = {https://dblp.org/rec/conf/nips/ZhengC00WZL0LXZ23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{rag,
  author       = {Patrick S. H. Lewis and
                  Ethan Perez and
                  Aleksandra Piktus and
                  Fabio Petroni and
                  Vladimir Karpukhin and
                  Naman Goyal and
                  Heinrich K{\"{u}}ttler and
                  Mike Lewis and
                  Wen{-}tau Yih and
                  Tim Rockt{\"{a}}schel and
                  Sebastian Riedel and
                  Douwe Kiela},
  editor       = {Hugo Larochelle and
                  Marc'Aurelio Ranzato and
                  Raia Hadsell and
                  Maria{-}Florina Balcan and
                  Hsuan{-}Tien Lin},
  title        = {Retrieval-Augmented Generation for Knowledge-Intensive {NLP} Tasks},
  booktitle    = {Advances in Neural Information Processing Systems 33: Annual Conference
                  on Neural Information Processing Systems 2020, NeurIPS 2020, December
                  6-12, 2020, virtual},
  year         = {2020},
  url          = {https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html},
  timestamp    = {Tue, 19 Jan 2021 15:57:07 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/LewisPPPKGKLYR020.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{bert-score,
  author       = {Tianyi Zhang and
                  Varsha Kishore and
                  Felix Wu and
                  Kilian Q. Weinberger and
                  Yoav Artzi},
  title        = {BERTScore: Evaluating Text Generation with {BERT}},
  booktitle    = {8th International Conference on Learning Representations, {ICLR} 2020,
                  Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher    = {OpenReview.net},
  year         = {2020},
  url          = {https://openreview.net/forum?id=SkeHuCVFDr},
  timestamp    = {Wed, 03 Jun 2020 10:08:32 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/ZhangKWWA20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{wei2022chain,
  author       = {Jason Wei and
                  Xuezhi Wang and
                  Dale Schuurmans and
                  Maarten Bosma and
                  Brian Ichter and
                  Fei Xia and
                  Ed H. Chi and
                  Quoc V. Le and
                  Denny Zhou},
  editor       = {Sanmi Koyejo and
                  S. Mohamed and
                  A. Agarwal and
                  Danielle Belgrave and
                  K. Cho and
                  A. Oh},
  title        = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  booktitle    = {Advances in Neural Information Processing Systems 35: Annual Conference
                  on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans,
                  LA, USA, November 28 - December 9, 2022},
  year         = {2022},
  url          = {http://papers.nips.cc/paper\_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html},
  timestamp    = {Mon, 08 Jan 2024 16:31:37 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/Wei0SBIXCLZ22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{singhal2023towards,
  title={Towards expert-level medical question answering with large language models},
  author={Singhal, Karan and Tu, Tao and Gottweis, Juraj and Sayres, Rory and Wulczyn, Ellery and Hou, Le and Clark, Kevin and Pfohl, Stephen and Cole-Lewis, Heather and Neal, Darlene and others},
  journal={arXiv preprint arXiv:2305.09617},
  year={2023}
}

@ARTICLE{10261199,
  author={Qiu, Jianing and Li, Lin and Sun, Jiankai and Peng, Jiachuan and Shi, Peilun and Zhang, Ruiyang and Dong, Yinzhao and Lam, Kyle and Lo, Frank P.-W. and Xiao, Bo and Yuan, Wu and Wang, Ningli and Xu, Dong and Lo, Benny},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Large AI Models in Health Informatics: Applications, Challenges, and the Future}, 
  year={2023},
  volume={27},
  number={12},
  pages={6074-6087},
  doi={10.1109/JBHI.2023.3316750}}

@misc{mixtral,
  doi = {10.48550/ARXIV.2401.04088},
  author = {Jiang,  Albert Q. and Sablayrolles,  Alexandre and Roux,  Antoine and Mensch,  Arthur and Savary,  Blanche and Bamford,  Chris and Chaplot,  Devendra Singh and Casas,  Diego de las and Hanna,  Emma Bou and Bressand,  Florian and Lengyel,  Gianna and Bour,  Guillaume and Lample,  Guillaume and Lavaud,  Lélio Renard and Saulnier,  Lucile and Lachaux,  Marie-Anne and Stock,  Pierre and Subramanian,  Sandeep and Yang,  Sophia and Antoniak,  Szymon and Scao,  Teven Le and Gervet,  Théophile and Lavril,  Thibaut and Wang,  Thomas and Lacroix,  Timothée and Sayed,  William El},
  keywords = {Machine Learning (cs.LG),  Computation and Language (cs.CL),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Mixtral of Experts},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}